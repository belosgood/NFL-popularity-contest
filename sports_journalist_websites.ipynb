{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup as bsoup\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test cell\n",
    "queries = [\"packers\",\"bears\",\"eagles\",\"cowboys\",\"raiders\",\"chiefs\"]\n",
    "nfl_info = defaultdict(list)\n",
    "\n",
    "for query in queries:\n",
    "    page_url = \"https://www.si.com/nfl/\" + query\n",
    "    nfl_info = NFLscrape(nfl_info, query)\n",
    "    \n",
    "test_df = pd.DataFrame(nfl_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def SI_NFLscrape(nfl_info, query):\n",
    "    page_url = \"https://www.si.com/nfl/\" + query\n",
    "\n",
    "    response = requests.get(page_url)\n",
    "    soup = bsoup(response.text, 'lxml')\n",
    "    si_url = re.compile(\"/nfl/\"+ query+\"/\\w+\")\n",
    "\n",
    "    for posting in set(soup.find_all('a')):\n",
    "        article_contents = \"\"\n",
    "        article_url = posting.get('href')\n",
    "        try:\n",
    "            if si_url.match(article_url):\n",
    "                article_url = \"https://www.si.com\" + article_url\n",
    "                article_response = requests.get(article_url)\n",
    "                article_soup = bsoup(response.text, 'lxml')\n",
    "                article_title = article_soup.h1\n",
    "                #article_author = article_soup.find_all('p', {\"class\":\"skpzhulc sk3x58id skh9fqbk\"})\n",
    "                texts = article_soup.find_all('p')\n",
    "                for text in texts:\n",
    "                    if text.text != \"Read More\": #and text.text not in [author.text for author in article_author]:\n",
    "                        article_contents += text.text        \n",
    "        except:\n",
    "            continue\n",
    "        finally:\n",
    "            nfl_info[\"Team\"].append(query)\n",
    "            nfl_info[\"Article URL\"].append(article_url)\n",
    "            nfl_info[\"Article Title\"].append(article_title)\n",
    "            #nfl_info[\"Article Author\"].append(article_author[0])\n",
    "            nfl_info[\"Text\"].append(article_contents)           \n",
    "    \n",
    "    return nfl_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ESPN_NFLscrape(nfl_info, query):\n",
    "    page_url = \"https://www.espn.com/blog/\" + query\n",
    "\n",
    "    response = requests.get(page_url)\n",
    "    soup = bsoup(response.text, 'lxml')\n",
    "\n",
    "    article_contents = \"\"\n",
    "    article_url = page_url\n",
    "    article_title = soup.find(\"header\", {\"class\": \"article-header\"}).text\n",
    "    #article_author = article_soup.find_all('div', {\"class\":\"author has-bio\"})\n",
    "    texts = soup.find_all('p')\n",
    "    \n",
    "    for text in texts:\n",
    "        article_contents += text.text        \n",
    "    nfl_info[\"Team\"].append(team_dict[query])\n",
    "    nfl_info[\"Article URL\"].append(article_url)\n",
    "    nfl_info[\"Article Title\"].append(article_title)\n",
    "    #nfl_info[\"Article Author\"].append(article_author[0])\n",
    "    nfl_info[\"Text\"].append(article_contents)           \n",
    "\n",
    "    return nfl_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\"las-vegas-raiders\", \"kansas-city-chiefs\", \"chicago-bears\", \"green-bay-packers\", \"dallas-cowboys\", \"philadelphia-eagles\"]\n",
    "team_dict = {\"las-vegas-raiders\": \"raiders\", \"kansas-city-chiefs\":\"chiefs\", \"chicago-bears\":\"bears\", \"green-bay-packers\":\"packers\", \"dallas-cowboys\":\"cowboys\", \"philadelphia-eagles\":\"eagles\"}\n",
    "nfl_info = defaultdict(list)\n",
    "\n",
    "for query in queries:\n",
    "    nfl_info = ESPN_NFLscrape(nfl_info, query)"
   ]
  },
  {
   "source": [
    "queries = [\"packers\",\"bears\",\"eagles\",\"cowboys\",\"raiders\",\"chiefs\"]\n",
    "for query in queries:\n",
    "    page_url = \"https://www.si.com/nfl/\" + query\n",
    "    nfl_info = SI_NFLscrape(nfl_info, query)\n",
    "    \n",
    "test_df = pd.DataFrame(nfl_info)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 98,
   "outputs": []
  }
 ]
}